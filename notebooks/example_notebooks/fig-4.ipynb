{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This file generates the data for Figure #4 from the paper https://arxiv.org/pdf/1806.06975.pdf\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import argparse\n",
    "import networkx as nx\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import sklearn\n",
    "import torch\n",
    "import datetime\n",
    "import matplotlib, matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from models.mlp import MLP\n",
    "from data import datasets\n",
    "from data.gene_graphs import GeneManiaGraph, RegNetGraph\n",
    "from data.utils import record_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torrent name: HiSeqV2.gz, Size: 513.04MB\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.TCGADataset()\n",
    "dataset.df = dataset.df - dataset.df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torrent name: regnet.pkl, Size: 8.81MB\n",
      "Torrent name: genemania.pkl, Size: 9.61MB\n"
     ]
    }
   ],
   "source": [
    "graphs = {\"regnet\": RegNetGraph(), \"genemania\": GeneManiaGraph()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Checkpointed Results\n"
     ]
    }
   ],
   "source": [
    "# Setup the results dictionary\n",
    "filename = \"../experiments/results/fig-4.pkl\"\n",
    "try:\n",
    "    results = pickle.load(open(filename, \"rb\"), encoding='latin1')\n",
    "    print(\"Loaded Checkpointed Results\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    results = pd.DataFrame(columns=['auc', 'gene', 'model', 'graph', 'is_first_degree', 'seed', 'train_size'])\n",
    "    print(\"Created a New Results Dictionary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping metric is accuracy_score\n"
     ]
    }
   ],
   "source": [
    "train_size = 50\n",
    "test_size = 1000\n",
    "trials = 3\n",
    "cuda = torch.cuda.is_available()\n",
    "models = {\"BasicMLP\": MLP(column_names=dataset.df.columns, dropout=False, cuda=cuda)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todo: 246345\n",
      "done: 20\n"
     ]
    }
   ],
   "source": [
    "# Create the set of all experiment ids and see which are left to do\n",
    "columns = [\"gene\", \"graph\", \"model\", \"seed\", \"is_first_degree\", \"train_size\"]\n",
    "all_exp_ids = [x for x in itertools.product(dataset.df.columns, graphs.keys(), models.keys(), range(trials), [True, False], [train_size])]\n",
    "all_exp_ids = pd.DataFrame(all_exp_ids, columns=columns)\n",
    "all_exp_ids.index = [\"-\".join(map(str, tup[1:])) for tup in all_exp_ids.itertuples(name=None)]\n",
    "results_exp_ids = results[columns].copy()\n",
    "results_exp_ids.index = [\"-\".join(map(str, tup[1:])) for tup in results_exp_ids.itertuples(name=None)]\n",
    "intersection_ids = all_exp_ids.index.intersection(results_exp_ids.index)\n",
    "todo = all_exp_ids.drop(intersection_ids).to_dict(orient=\"records\")\n",
    "\n",
    "print(\"todo: \" + str(len(todo)))\n",
    "print(\"done: \" + str(len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "  batch (0/40), train loss:0.7699\n",
      "  batch (10/40), train loss:0.7334\n",
      "  batch (20/40), train loss:0.5974\n",
      "  batch (30/40), train loss:0.7164\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7689\n",
      "  batch (10/40), train loss:0.7329\n",
      "  batch (20/40), train loss:0.5976\n",
      "  batch (30/40), train loss:0.7161\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7683\n",
      "  batch (10/40), train loss:0.7324\n",
      "  batch (20/40), train loss:0.5979\n",
      "  batch (30/40), train loss:0.7158\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7677\n",
      "  batch (10/40), train loss:0.7320\n",
      "  batch (20/40), train loss:0.5981\n",
      "  batch (30/40), train loss:0.7155\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7672\n",
      "  batch (10/40), train loss:0.7315\n",
      "  batch (20/40), train loss:0.5983\n",
      "  batch (30/40), train loss:0.7152\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7666\n",
      "  batch (10/40), train loss:0.7311\n",
      "  batch (20/40), train loss:0.5985\n",
      "  batch (30/40), train loss:0.7149\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7661\n",
      "  batch (10/40), train loss:0.7307\n",
      "  batch (20/40), train loss:0.5988\n",
      "  batch (30/40), train loss:0.7146\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7656\n",
      "  batch (10/40), train loss:0.7303\n",
      "  batch (20/40), train loss:0.5990\n",
      "  batch (30/40), train loss:0.7144\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7650\n",
      "  batch (10/40), train loss:0.7298\n",
      "  batch (20/40), train loss:0.5992\n",
      "  batch (30/40), train loss:0.7141\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7645\n",
      "  batch (10/40), train loss:0.7294\n",
      "  batch (20/40), train loss:0.5994\n",
      "  batch (30/40), train loss:0.7138\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7640\n",
      "  batch (10/40), train loss:0.7289\n",
      "  batch (20/40), train loss:0.5996\n",
      "  batch (30/40), train loss:0.7135\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7635\n",
      "  batch (10/40), train loss:0.7285\n",
      "  batch (20/40), train loss:0.5998\n",
      "  batch (30/40), train loss:0.7133\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7629\n",
      "  batch (10/40), train loss:0.7281\n",
      "  batch (20/40), train loss:0.6000\n",
      "  batch (30/40), train loss:0.7130\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7624\n",
      "  batch (10/40), train loss:0.7277\n",
      "  batch (20/40), train loss:0.6002\n",
      "  batch (30/40), train loss:0.7127\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7619\n",
      "  batch (10/40), train loss:0.7272\n",
      "  batch (20/40), train loss:0.6004\n",
      "  batch (30/40), train loss:0.7125\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7614\n",
      "  batch (10/40), train loss:0.7268\n",
      "  batch (20/40), train loss:0.6006\n",
      "  batch (30/40), train loss:0.7122\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7608\n",
      "  batch (10/40), train loss:0.7264\n",
      "  batch (20/40), train loss:0.6008\n",
      "  batch (30/40), train loss:0.7119\n",
      "total train time:0.10 for epochs: 16\n",
      "  batch (0/40), train loss:0.6887\n",
      "  batch (10/40), train loss:0.7136\n",
      "  batch (20/40), train loss:0.6801\n",
      "  batch (30/40), train loss:0.6022\n",
      "epoch: 0, time: 0.00, valid_metric: 0.70, train_metric: 0.90\n",
      "  batch (0/40), train loss:0.4590\n",
      "  batch (10/40), train loss:0.5599\n",
      "  batch (20/40), train loss:0.5196\n",
      "  batch (30/40), train loss:0.4532\n",
      "epoch: 1, time: 0.00, valid_metric: 0.70, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.3434\n",
      "  batch (10/40), train loss:0.4635\n",
      "  batch (20/40), train loss:0.3954\n",
      "  batch (30/40), train loss:0.3508\n",
      "epoch: 2, time: 0.00, valid_metric: 0.80, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2663\n",
      "  batch (10/40), train loss:0.3919\n",
      "  batch (20/40), train loss:0.3071\n",
      "  batch (30/40), train loss:0.2771\n",
      "epoch: 3, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2120\n",
      "  batch (10/40), train loss:0.3342\n",
      "  batch (20/40), train loss:0.2392\n",
      "  batch (30/40), train loss:0.2171\n",
      "epoch: 4, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1747\n",
      "  batch (10/40), train loss:0.2975\n",
      "  batch (20/40), train loss:0.1916\n",
      "  batch (30/40), train loss:0.1731\n",
      "epoch: 5, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1431\n",
      "  batch (10/40), train loss:0.2584\n",
      "  batch (20/40), train loss:0.1562\n",
      "  batch (30/40), train loss:0.1415\n",
      "epoch: 6, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1186\n",
      "  batch (10/40), train loss:0.2349\n",
      "  batch (20/40), train loss:0.1291\n",
      "  batch (30/40), train loss:0.1180\n",
      "epoch: 7, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0983\n",
      "  batch (10/40), train loss:0.2081\n",
      "  batch (20/40), train loss:0.1075\n",
      "  batch (30/40), train loss:0.1000\n",
      "epoch: 8, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0820\n",
      "  batch (10/40), train loss:0.1793\n",
      "  batch (20/40), train loss:0.0916\n",
      "  batch (30/40), train loss:0.0861\n",
      "epoch: 9, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0692\n",
      "  batch (10/40), train loss:0.1558\n",
      "  batch (20/40), train loss:0.0790\n",
      "  batch (30/40), train loss:0.0751\n",
      "epoch: 10, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0590\n",
      "  batch (10/40), train loss:0.1287\n",
      "  batch (20/40), train loss:0.0681\n",
      "  batch (30/40), train loss:0.0655\n",
      "epoch: 11, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0509\n",
      "  batch (10/40), train loss:0.1064\n",
      "  batch (20/40), train loss:0.0591\n",
      "  batch (30/40), train loss:0.0569\n",
      "epoch: 12, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0445\n",
      "  batch (10/40), train loss:0.0879\n",
      "  batch (20/40), train loss:0.0518\n",
      "  batch (30/40), train loss:0.0498\n",
      "epoch: 13, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0394\n",
      "  batch (10/40), train loss:0.0737\n",
      "  batch (20/40), train loss:0.0457\n",
      "  batch (30/40), train loss:0.0440\n",
      "epoch: 14, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0352\n",
      "  batch (10/40), train loss:0.0625\n",
      "  batch (20/40), train loss:0.0406\n",
      "  batch (30/40), train loss:0.0394\n",
      "epoch: 15, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0317\n",
      "  batch (10/40), train loss:0.0538\n",
      "  batch (20/40), train loss:0.0365\n",
      "  batch (30/40), train loss:0.0355\n",
      "epoch: 16, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0286\n",
      "  batch (10/40), train loss:0.0470\n",
      "  batch (20/40), train loss:0.0329\n",
      "  batch (30/40), train loss:0.0319\n",
      "epoch: 17, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0259\n",
      "  batch (10/40), train loss:0.0417\n",
      "  batch (20/40), train loss:0.0298\n",
      "  batch (30/40), train loss:0.0287\n",
      "epoch: 18, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0237\n",
      "  batch (10/40), train loss:0.0375\n",
      "  batch (20/40), train loss:0.0271\n",
      "  batch (30/40), train loss:0.0259\n",
      "epoch: 19, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0217\n",
      "  batch (10/40), train loss:0.0339\n",
      "  batch (20/40), train loss:0.0247\n",
      "  batch (30/40), train loss:0.0235\n",
      "epoch: 20, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0200\n",
      "  batch (10/40), train loss:0.0308\n",
      "  batch (20/40), train loss:0.0227\n",
      "  batch (30/40), train loss:0.0214\n",
      "epoch: 21, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0185\n",
      "  batch (10/40), train loss:0.0281\n",
      "  batch (20/40), train loss:0.0209\n",
      "  batch (30/40), train loss:0.0197\n",
      "epoch: 22, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0172\n",
      "  batch (10/40), train loss:0.0258\n",
      "  batch (20/40), train loss:0.0194\n",
      "  batch (30/40), train loss:0.0181\n",
      "epoch: 23, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0161\n",
      "  batch (10/40), train loss:0.0239\n",
      "  batch (20/40), train loss:0.0180\n",
      "  batch (30/40), train loss:0.0168\n",
      "epoch: 24, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0151\n",
      "  batch (10/40), train loss:0.0221\n",
      "  batch (20/40), train loss:0.0169\n",
      "  batch (30/40), train loss:0.0156\n",
      "epoch: 25, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0142\n",
      "  batch (10/40), train loss:0.0205\n",
      "  batch (20/40), train loss:0.0159\n",
      "  batch (30/40), train loss:0.0145\n",
      "epoch: 26, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0133\n",
      "  batch (10/40), train loss:0.0192\n",
      "  batch (20/40), train loss:0.0149\n",
      "  batch (30/40), train loss:0.0136\n",
      "epoch: 27, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0125\n",
      "  batch (10/40), train loss:0.0179\n",
      "  batch (20/40), train loss:0.0140\n",
      "  batch (30/40), train loss:0.0128\n",
      "epoch: 28, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0119\n",
      "  batch (10/40), train loss:0.0168\n",
      "  batch (20/40), train loss:0.0132\n",
      "  batch (30/40), train loss:0.0120\n",
      "epoch: 29, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0112\n",
      "  batch (10/40), train loss:0.0158\n",
      "  batch (20/40), train loss:0.0125\n",
      "  batch (30/40), train loss:0.0113\n",
      "epoch: 30, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0107\n",
      "  batch (10/40), train loss:0.0149\n",
      "  batch (20/40), train loss:0.0119\n",
      "  batch (30/40), train loss:0.0107\n",
      "epoch: 31, time: 0.01, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0101\n",
      "  batch (10/40), train loss:0.0141\n",
      "  batch (20/40), train loss:0.0113\n",
      "  batch (30/40), train loss:0.0101\n",
      "epoch: 32, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0096\n",
      "  batch (10/40), train loss:0.0133\n",
      "  batch (20/40), train loss:0.0107\n",
      "  batch (30/40), train loss:0.0096\n",
      "total train time:0.70 for epochs: 33\n",
      "  batch (0/40), train loss:0.6995\n",
      "  batch (10/40), train loss:0.6775\n",
      "  batch (20/40), train loss:0.6929\n",
      "  batch (30/40), train loss:0.7098\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.42\n",
      "  batch (0/40), train loss:0.6990\n",
      "  batch (10/40), train loss:0.6769\n",
      "  batch (20/40), train loss:0.6926\n",
      "  batch (30/40), train loss:0.7095\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6988\n",
      "  batch (10/40), train loss:0.6765\n",
      "  batch (20/40), train loss:0.6924\n",
      "  batch (30/40), train loss:0.7092\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6986\n",
      "  batch (10/40), train loss:0.6761\n",
      "  batch (20/40), train loss:0.6923\n",
      "  batch (30/40), train loss:0.7088\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6985\n",
      "  batch (10/40), train loss:0.6757\n",
      "  batch (20/40), train loss:0.6921\n",
      "  batch (30/40), train loss:0.7084\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6984\n",
      "  batch (10/40), train loss:0.6753\n",
      "  batch (20/40), train loss:0.6920\n",
      "  batch (30/40), train loss:0.7080\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6983\n",
      "  batch (10/40), train loss:0.6749\n",
      "  batch (20/40), train loss:0.6919\n",
      "  batch (30/40), train loss:0.7076\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6982\n",
      "  batch (10/40), train loss:0.6746\n",
      "  batch (20/40), train loss:0.6918\n",
      "  batch (30/40), train loss:0.7072\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6981\n",
      "  batch (10/40), train loss:0.6742\n",
      "  batch (20/40), train loss:0.6917\n",
      "  batch (30/40), train loss:0.7068\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6980\n",
      "  batch (10/40), train loss:0.6738\n",
      "  batch (20/40), train loss:0.6916\n",
      "  batch (30/40), train loss:0.7064\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6979\n",
      "  batch (10/40), train loss:0.6734\n",
      "  batch (20/40), train loss:0.6915\n",
      "  batch (30/40), train loss:0.7061\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6978\n",
      "  batch (10/40), train loss:0.6731\n",
      "  batch (20/40), train loss:0.6915\n",
      "  batch (30/40), train loss:0.7057\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6977\n",
      "  batch (10/40), train loss:0.6727\n",
      "  batch (20/40), train loss:0.6914\n",
      "  batch (30/40), train loss:0.7053\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6976\n",
      "  batch (10/40), train loss:0.6723\n",
      "  batch (20/40), train loss:0.6914\n",
      "  batch (30/40), train loss:0.7050\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6975\n",
      "  batch (10/40), train loss:0.6719\n",
      "  batch (20/40), train loss:0.6913\n",
      "  batch (30/40), train loss:0.7046\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6974\n",
      "  batch (10/40), train loss:0.6716\n",
      "  batch (20/40), train loss:0.6913\n",
      "  batch (30/40), train loss:0.7043\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6973\n",
      "  batch (10/40), train loss:0.6712\n",
      "  batch (20/40), train loss:0.6912\n",
      "  batch (30/40), train loss:0.7039\n",
      "total train time:0.11 for epochs: 16\n",
      "  batch (0/40), train loss:0.6961\n",
      "  batch (10/40), train loss:0.6608\n",
      "  batch (20/40), train loss:0.6947\n",
      "  batch (30/40), train loss:0.6394\n",
      "epoch: 0, time: 0.00, valid_metric: 0.70, train_metric: 0.88\n",
      "  batch (0/40), train loss:0.4945\n",
      "  batch (10/40), train loss:0.5027\n",
      "  batch (20/40), train loss:0.5144\n",
      "  batch (30/40), train loss:0.4658\n",
      "epoch: 1, time: 0.00, valid_metric: 0.70, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.4079\n",
      "  batch (10/40), train loss:0.3999\n",
      "  batch (20/40), train loss:0.3898\n",
      "  batch (30/40), train loss:0.3382\n",
      "epoch: 2, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.3362\n",
      "  batch (10/40), train loss:0.3101\n",
      "  batch (20/40), train loss:0.3171\n",
      "  batch (30/40), train loss:0.2430\n",
      "epoch: 3, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2611\n",
      "  batch (10/40), train loss:0.2391\n",
      "  batch (20/40), train loss:0.2619\n",
      "  batch (30/40), train loss:0.1808\n",
      "epoch: 4, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1993\n",
      "  batch (10/40), train loss:0.1905\n",
      "  batch (20/40), train loss:0.2199\n",
      "  batch (30/40), train loss:0.1398\n",
      "epoch: 5, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1530\n",
      "  batch (10/40), train loss:0.1576\n",
      "  batch (20/40), train loss:0.1875\n",
      "  batch (30/40), train loss:0.1097\n",
      "epoch: 6, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1206\n",
      "  batch (10/40), train loss:0.1376\n",
      "  batch (20/40), train loss:0.1609\n",
      "  batch (30/40), train loss:0.0868\n",
      "epoch: 7, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0958\n",
      "  batch (10/40), train loss:0.1219\n",
      "  batch (20/40), train loss:0.1395\n",
      "  batch (30/40), train loss:0.0680\n",
      "epoch: 8, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0766\n",
      "  batch (10/40), train loss:0.1081\n",
      "  batch (20/40), train loss:0.1221\n",
      "  batch (30/40), train loss:0.0542\n",
      "epoch: 9, time: 0.01, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0626\n",
      "  batch (10/40), train loss:0.0936\n",
      "  batch (20/40), train loss:0.1094\n",
      "  batch (30/40), train loss:0.0429\n",
      "epoch: 10, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0520\n",
      "  batch (10/40), train loss:0.0757\n",
      "  batch (20/40), train loss:0.0947\n",
      "  batch (30/40), train loss:0.0342\n",
      "epoch: 11, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0441\n",
      "  batch (10/40), train loss:0.0646\n",
      "  batch (20/40), train loss:0.0785\n",
      "  batch (30/40), train loss:0.0275\n",
      "epoch: 12, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0384\n",
      "  batch (10/40), train loss:0.0544\n",
      "  batch (20/40), train loss:0.0662\n",
      "  batch (30/40), train loss:0.0232\n",
      "epoch: 13, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0338\n",
      "  batch (10/40), train loss:0.0448\n",
      "  batch (20/40), train loss:0.0555\n",
      "  batch (30/40), train loss:0.0197\n",
      "epoch: 14, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0302\n",
      "  batch (10/40), train loss:0.0368\n",
      "  batch (20/40), train loss:0.0462\n",
      "  batch (30/40), train loss:0.0176\n",
      "epoch: 15, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0275\n",
      "  batch (10/40), train loss:0.0306\n",
      "  batch (20/40), train loss:0.0397\n",
      "  batch (30/40), train loss:0.0158\n",
      "total train time:0.43 for epochs: 16\n",
      "  batch (0/40), train loss:0.6697\n",
      "  batch (10/40), train loss:0.7053\n",
      "  batch (20/40), train loss:0.6823\n",
      "  batch (30/40), train loss:0.6802\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.57\n",
      "  batch (0/40), train loss:0.6679\n",
      "  batch (10/40), train loss:0.7056\n",
      "  batch (20/40), train loss:0.6811\n",
      "  batch (30/40), train loss:0.6797\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.57\n",
      "  batch (0/40), train loss:0.6664\n",
      "  batch (10/40), train loss:0.7060\n",
      "  batch (20/40), train loss:0.6798\n",
      "  batch (30/40), train loss:0.6792\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.57\n",
      "  batch (0/40), train loss:0.6649\n",
      "  batch (10/40), train loss:0.7064\n",
      "  batch (20/40), train loss:0.6786\n",
      "  batch (30/40), train loss:0.6787\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6635\n",
      "  batch (10/40), train loss:0.7068\n",
      "  batch (20/40), train loss:0.6774\n",
      "  batch (30/40), train loss:0.6782\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6621\n",
      "  batch (10/40), train loss:0.7072\n",
      "  batch (20/40), train loss:0.6762\n",
      "  batch (30/40), train loss:0.6777\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6607\n",
      "  batch (10/40), train loss:0.7075\n",
      "  batch (20/40), train loss:0.6750\n",
      "  batch (30/40), train loss:0.6772\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6593\n",
      "  batch (10/40), train loss:0.7079\n",
      "  batch (20/40), train loss:0.6739\n",
      "  batch (30/40), train loss:0.6767\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6580\n",
      "  batch (10/40), train loss:0.7083\n",
      "  batch (20/40), train loss:0.6727\n",
      "  batch (30/40), train loss:0.6762\n",
      "epoch: 8, time: 0.00, valid_metric: 0.60, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6566\n",
      "  batch (10/40), train loss:0.7087\n",
      "  batch (20/40), train loss:0.6716\n",
      "  batch (30/40), train loss:0.6758\n",
      "epoch: 9, time: 0.00, valid_metric: 0.60, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6553\n",
      "  batch (10/40), train loss:0.7090\n",
      "  batch (20/40), train loss:0.6705\n",
      "  batch (30/40), train loss:0.6753\n",
      "epoch: 10, time: 0.00, valid_metric: 0.60, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6540\n",
      "  batch (10/40), train loss:0.7094\n",
      "  batch (20/40), train loss:0.6694\n",
      "  batch (30/40), train loss:0.6749\n",
      "epoch: 11, time: 0.00, valid_metric: 0.60, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6528\n",
      "  batch (10/40), train loss:0.7098\n",
      "  batch (20/40), train loss:0.6682\n",
      "  batch (30/40), train loss:0.6745\n",
      "epoch: 12, time: 0.00, valid_metric: 0.60, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6515\n",
      "  batch (10/40), train loss:0.7101\n",
      "  batch (20/40), train loss:0.6671\n",
      "  batch (30/40), train loss:0.6740\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6503\n",
      "  batch (10/40), train loss:0.7105\n",
      "  batch (20/40), train loss:0.6660\n",
      "  batch (30/40), train loss:0.6736\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6490\n",
      "  batch (10/40), train loss:0.7108\n",
      "  batch (20/40), train loss:0.6649\n",
      "  batch (30/40), train loss:0.6731\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6478\n",
      "  batch (10/40), train loss:0.7112\n",
      "  batch (20/40), train loss:0.6637\n",
      "  batch (30/40), train loss:0.6727\n",
      "epoch: 16, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6466\n",
      "  batch (10/40), train loss:0.7115\n",
      "  batch (20/40), train loss:0.6626\n",
      "  batch (30/40), train loss:0.6723\n",
      "epoch: 17, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6454\n",
      "  batch (10/40), train loss:0.7119\n",
      "  batch (20/40), train loss:0.6615\n",
      "  batch (30/40), train loss:0.6718\n",
      "total train time:0.13 for epochs: 18\n",
      "  batch (0/40), train loss:0.6854\n",
      "  batch (10/40), train loss:0.6491\n",
      "  batch (20/40), train loss:0.7251\n",
      "  batch (30/40), train loss:0.6559\n",
      "epoch: 0, time: 0.00, valid_metric: 0.60, train_metric: 0.85\n",
      "  batch (0/40), train loss:0.4624\n",
      "  batch (10/40), train loss:0.4270\n",
      "  batch (20/40), train loss:0.5581\n",
      "  batch (30/40), train loss:0.4692\n",
      "epoch: 1, time: 0.00, valid_metric: 0.60, train_metric: 0.88\n",
      "  batch (0/40), train loss:0.3665\n",
      "  batch (10/40), train loss:0.2904\n",
      "  batch (20/40), train loss:0.4720\n",
      "  batch (30/40), train loss:0.3255\n",
      "epoch: 2, time: 0.00, valid_metric: 0.60, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.3036\n",
      "  batch (10/40), train loss:0.2180\n",
      "  batch (20/40), train loss:0.4200\n",
      "  batch (30/40), train loss:0.2186\n",
      "epoch: 3, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2548\n",
      "  batch (10/40), train loss:0.1717\n",
      "  batch (20/40), train loss:0.3799\n",
      "  batch (30/40), train loss:0.1582\n",
      "epoch: 4, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2073\n",
      "  batch (10/40), train loss:0.1381\n",
      "  batch (20/40), train loss:0.3539\n",
      "  batch (30/40), train loss:0.1253\n",
      "epoch: 5, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1691\n",
      "  batch (10/40), train loss:0.1126\n",
      "  batch (20/40), train loss:0.3292\n",
      "  batch (30/40), train loss:0.1047\n",
      "epoch: 6, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1429\n",
      "  batch (10/40), train loss:0.0935\n",
      "  batch (20/40), train loss:0.3121\n",
      "  batch (30/40), train loss:0.0912\n",
      "epoch: 7, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1215\n",
      "  batch (10/40), train loss:0.0776\n",
      "  batch (20/40), train loss:0.2931\n",
      "  batch (30/40), train loss:0.0830\n",
      "epoch: 8, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1031\n",
      "  batch (10/40), train loss:0.0654\n",
      "  batch (20/40), train loss:0.2806\n",
      "  batch (30/40), train loss:0.0771\n",
      "epoch: 9, time: 0.01, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0855\n",
      "  batch (10/40), train loss:0.0558\n",
      "  batch (20/40), train loss:0.2718\n",
      "  batch (30/40), train loss:0.0726\n",
      "epoch: 10, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0727\n",
      "  batch (10/40), train loss:0.0484\n",
      "  batch (20/40), train loss:0.2588\n",
      "  batch (30/40), train loss:0.0695\n",
      "epoch: 11, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0627\n",
      "  batch (10/40), train loss:0.0421\n",
      "  batch (20/40), train loss:0.2495\n",
      "  batch (30/40), train loss:0.0666\n",
      "epoch: 12, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0541\n",
      "  batch (10/40), train loss:0.0369\n",
      "  batch (20/40), train loss:0.2392\n",
      "  batch (30/40), train loss:0.0638\n",
      "epoch: 13, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0467\n",
      "  batch (10/40), train loss:0.0328\n",
      "  batch (20/40), train loss:0.2304\n",
      "  batch (30/40), train loss:0.0619\n",
      "epoch: 14, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0410\n",
      "  batch (10/40), train loss:0.0293\n",
      "  batch (20/40), train loss:0.2204\n",
      "  batch (30/40), train loss:0.0595\n",
      "epoch: 15, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0357\n",
      "  batch (10/40), train loss:0.0263\n",
      "  batch (20/40), train loss:0.2169\n",
      "  batch (30/40), train loss:0.0569\n",
      "epoch: 16, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0318\n",
      "  batch (10/40), train loss:0.0240\n",
      "  batch (20/40), train loss:0.2016\n",
      "  batch (30/40), train loss:0.0541\n",
      "epoch: 17, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0292\n",
      "  batch (10/40), train loss:0.0220\n",
      "  batch (20/40), train loss:0.1940\n",
      "  batch (30/40), train loss:0.0523\n",
      "epoch: 18, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0268\n",
      "  batch (10/40), train loss:0.0202\n",
      "  batch (20/40), train loss:0.1846\n",
      "  batch (30/40), train loss:0.0496\n",
      "epoch: 19, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0244\n",
      "  batch (10/40), train loss:0.0186\n",
      "  batch (20/40), train loss:0.1752\n",
      "  batch (30/40), train loss:0.0474\n",
      "epoch: 20, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0225\n",
      "  batch (10/40), train loss:0.0175\n",
      "  batch (20/40), train loss:0.1682\n",
      "  batch (30/40), train loss:0.0451\n",
      "epoch: 21, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0215\n",
      "  batch (10/40), train loss:0.0164\n",
      "  batch (20/40), train loss:0.1616\n",
      "  batch (30/40), train loss:0.0431\n",
      "epoch: 22, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0204\n",
      "  batch (10/40), train loss:0.0156\n",
      "  batch (20/40), train loss:0.1555\n",
      "  batch (30/40), train loss:0.0410\n",
      "epoch: 23, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0190\n",
      "  batch (10/40), train loss:0.0147\n",
      "  batch (20/40), train loss:0.1496\n",
      "  batch (30/40), train loss:0.0387\n",
      "epoch: 24, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0177\n",
      "  batch (10/40), train loss:0.0138\n",
      "  batch (20/40), train loss:0.1443\n",
      "  batch (30/40), train loss:0.0368\n",
      "epoch: 25, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0167\n",
      "  batch (10/40), train loss:0.0131\n",
      "  batch (20/40), train loss:0.1391\n",
      "  batch (30/40), train loss:0.0349\n",
      "total train time:0.71 for epochs: 26\n",
      "  batch (0/40), train loss:0.6478\n",
      "  batch (10/40), train loss:0.7266\n",
      "  batch (20/40), train loss:0.6755\n",
      "  batch (30/40), train loss:0.6159\n",
      "epoch: 0, time: 0.00, valid_metric: 1.00, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.4556\n",
      "  batch (10/40), train loss:0.4904\n",
      "  batch (20/40), train loss:0.4886\n",
      "  batch (30/40), train loss:0.4546\n",
      "epoch: 1, time: 0.00, valid_metric: 1.00, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.3884\n",
      "  batch (10/40), train loss:0.3170\n",
      "  batch (20/40), train loss:0.3782\n",
      "  batch (30/40), train loss:0.3394\n",
      "epoch: 2, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2845\n",
      "  batch (10/40), train loss:0.2239\n",
      "  batch (20/40), train loss:0.3029\n",
      "  batch (30/40), train loss:0.2599\n",
      "epoch: 3, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2040\n",
      "  batch (10/40), train loss:0.1693\n",
      "  batch (20/40), train loss:0.2436\n",
      "  batch (30/40), train loss:0.2007\n",
      "epoch: 4, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1545\n",
      "  batch (10/40), train loss:0.1302\n",
      "  batch (20/40), train loss:0.1958\n",
      "  batch (30/40), train loss:0.1575\n",
      "epoch: 5, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1172\n",
      "  batch (10/40), train loss:0.1039\n",
      "  batch (20/40), train loss:0.1601\n",
      "  batch (30/40), train loss:0.1223\n",
      "epoch: 6, time: 0.01, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0921\n",
      "  batch (10/40), train loss:0.0846\n",
      "  batch (20/40), train loss:0.1324\n",
      "  batch (30/40), train loss:0.0964\n",
      "epoch: 7, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0732\n",
      "  batch (10/40), train loss:0.0696\n",
      "  batch (20/40), train loss:0.1149\n",
      "  batch (30/40), train loss:0.0782\n",
      "epoch: 8, time: 0.01, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0598\n",
      "  batch (10/40), train loss:0.0582\n",
      "  batch (20/40), train loss:0.1020\n",
      "  batch (30/40), train loss:0.0646\n",
      "epoch: 9, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0500\n",
      "  batch (10/40), train loss:0.0497\n",
      "  batch (20/40), train loss:0.0901\n",
      "  batch (30/40), train loss:0.0537\n",
      "epoch: 10, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0428\n",
      "  batch (10/40), train loss:0.0428\n",
      "  batch (20/40), train loss:0.0799\n",
      "  batch (30/40), train loss:0.0453\n",
      "epoch: 11, time: 0.01, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0376\n",
      "  batch (10/40), train loss:0.0374\n",
      "  batch (20/40), train loss:0.0662\n",
      "  batch (30/40), train loss:0.0393\n",
      "epoch: 12, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0333\n",
      "  batch (10/40), train loss:0.0330\n",
      "  batch (20/40), train loss:0.0540\n",
      "  batch (30/40), train loss:0.0345\n",
      "epoch: 13, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0302\n",
      "  batch (10/40), train loss:0.0293\n",
      "  batch (20/40), train loss:0.0445\n",
      "  batch (30/40), train loss:0.0305\n",
      "epoch: 14, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0274\n",
      "  batch (10/40), train loss:0.0265\n",
      "  batch (20/40), train loss:0.0349\n",
      "  batch (30/40), train loss:0.0272\n",
      "epoch: 15, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0248\n",
      "  batch (10/40), train loss:0.0241\n",
      "  batch (20/40), train loss:0.0279\n",
      "  batch (30/40), train loss:0.0245\n",
      "total train time:0.44 for epochs: 16\n",
      "  batch (0/40), train loss:0.6822\n",
      "  batch (10/40), train loss:0.6954\n",
      "  batch (20/40), train loss:0.7354\n",
      "  batch (30/40), train loss:0.6821\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6822\n",
      "  batch (10/40), train loss:0.6953\n",
      "  batch (20/40), train loss:0.7345\n",
      "  batch (30/40), train loss:0.6823\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6823\n",
      "  batch (10/40), train loss:0.6952\n",
      "  batch (20/40), train loss:0.7336\n",
      "  batch (30/40), train loss:0.6825\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6825\n",
      "  batch (10/40), train loss:0.6951\n",
      "  batch (20/40), train loss:0.7326\n",
      "  batch (30/40), train loss:0.6827\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6827\n",
      "  batch (10/40), train loss:0.6950\n",
      "  batch (20/40), train loss:0.7317\n",
      "  batch (30/40), train loss:0.6828\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6829\n",
      "  batch (10/40), train loss:0.6950\n",
      "  batch (20/40), train loss:0.7308\n",
      "  batch (30/40), train loss:0.6830\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6831\n",
      "  batch (10/40), train loss:0.6949\n",
      "  batch (20/40), train loss:0.7299\n",
      "  batch (30/40), train loss:0.6832\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6833\n",
      "  batch (10/40), train loss:0.6948\n",
      "  batch (20/40), train loss:0.7290\n",
      "  batch (30/40), train loss:0.6834\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6835\n",
      "  batch (10/40), train loss:0.6947\n",
      "  batch (20/40), train loss:0.7282\n",
      "  batch (30/40), train loss:0.6836\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6837\n",
      "  batch (10/40), train loss:0.6946\n",
      "  batch (20/40), train loss:0.7273\n",
      "  batch (30/40), train loss:0.6838\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6838\n",
      "  batch (10/40), train loss:0.6946\n",
      "  batch (20/40), train loss:0.7265\n",
      "  batch (30/40), train loss:0.6840\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6840\n",
      "  batch (10/40), train loss:0.6945\n",
      "  batch (20/40), train loss:0.7256\n",
      "  batch (30/40), train loss:0.6842\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6842\n",
      "  batch (10/40), train loss:0.6944\n",
      "  batch (20/40), train loss:0.7248\n",
      "  batch (30/40), train loss:0.6844\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6844\n",
      "  batch (10/40), train loss:0.6944\n",
      "  batch (20/40), train loss:0.7240\n",
      "  batch (30/40), train loss:0.6846\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6846\n",
      "  batch (10/40), train loss:0.6943\n",
      "  batch (20/40), train loss:0.7232\n",
      "  batch (30/40), train loss:0.6847\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6848\n",
      "  batch (10/40), train loss:0.6943\n",
      "  batch (20/40), train loss:0.7224\n",
      "  batch (30/40), train loss:0.6849\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6850\n",
      "  batch (10/40), train loss:0.6942\n",
      "  batch (20/40), train loss:0.7216\n",
      "  batch (30/40), train loss:0.6851\n",
      "total train time:0.12 for epochs: 16\n",
      "  batch (0/40), train loss:0.6884\n",
      "  batch (10/40), train loss:0.7265\n",
      "  batch (20/40), train loss:0.6709\n",
      "  batch (30/40), train loss:0.6916\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.88\n",
      "  batch (0/40), train loss:0.5034\n",
      "  batch (10/40), train loss:0.5325\n",
      "  batch (20/40), train loss:0.4933\n",
      "  batch (30/40), train loss:0.5541\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.4268\n",
      "  batch (10/40), train loss:0.4080\n",
      "  batch (20/40), train loss:0.3566\n",
      "  batch (30/40), train loss:0.4372\n",
      "epoch: 2, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.3517\n",
      "  batch (10/40), train loss:0.3078\n",
      "  batch (20/40), train loss:0.2545\n",
      "  batch (30/40), train loss:0.3481\n",
      "epoch: 3, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2890\n",
      "  batch (10/40), train loss:0.2317\n",
      "  batch (20/40), train loss:0.1879\n",
      "  batch (30/40), train loss:0.2796\n",
      "epoch: 4, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2334\n",
      "  batch (10/40), train loss:0.1761\n",
      "  batch (20/40), train loss:0.1459\n",
      "  batch (30/40), train loss:0.2227\n",
      "epoch: 5, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1912\n",
      "  batch (10/40), train loss:0.1370\n",
      "  batch (20/40), train loss:0.1140\n",
      "  batch (30/40), train loss:0.1794\n",
      "epoch: 6, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1590\n",
      "  batch (10/40), train loss:0.1059\n",
      "  batch (20/40), train loss:0.0905\n",
      "  batch (30/40), train loss:0.1468\n",
      "epoch: 7, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1337\n",
      "  batch (10/40), train loss:0.0825\n",
      "  batch (20/40), train loss:0.0731\n",
      "  batch (30/40), train loss:0.1220\n",
      "epoch: 8, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1132\n",
      "  batch (10/40), train loss:0.0656\n",
      "  batch (20/40), train loss:0.0599\n",
      "  batch (30/40), train loss:0.1027\n",
      "epoch: 9, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0966\n",
      "  batch (10/40), train loss:0.0532\n",
      "  batch (20/40), train loss:0.0504\n",
      "  batch (30/40), train loss:0.0872\n",
      "epoch: 10, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0833\n",
      "  batch (10/40), train loss:0.0440\n",
      "  batch (20/40), train loss:0.0432\n",
      "  batch (30/40), train loss:0.0749\n",
      "epoch: 11, time: 0.01, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0726\n",
      "  batch (10/40), train loss:0.0372\n",
      "  batch (20/40), train loss:0.0373\n",
      "  batch (30/40), train loss:0.0633\n",
      "epoch: 12, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0632\n",
      "  batch (10/40), train loss:0.0321\n",
      "  batch (20/40), train loss:0.0326\n",
      "  batch (30/40), train loss:0.0542\n",
      "epoch: 13, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0543\n",
      "  batch (10/40), train loss:0.0281\n",
      "  batch (20/40), train loss:0.0286\n",
      "  batch (30/40), train loss:0.0472\n",
      "epoch: 14, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0464\n",
      "  batch (10/40), train loss:0.0250\n",
      "  batch (20/40), train loss:0.0251\n",
      "  batch (30/40), train loss:0.0417\n",
      "epoch: 15, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0399\n",
      "  batch (10/40), train loss:0.0224\n",
      "  batch (20/40), train loss:0.0223\n",
      "  batch (30/40), train loss:0.0373\n",
      "total train time:0.42 for epochs: 16\n",
      "  batch (0/40), train loss:0.7393\n",
      "  batch (10/40), train loss:0.7068\n",
      "  batch (20/40), train loss:0.7199\n",
      "  batch (30/40), train loss:0.7303\n",
      "epoch: 0, time: 0.00, valid_metric: 0.40, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7375\n",
      "  batch (10/40), train loss:0.7063\n",
      "  batch (20/40), train loss:0.7177\n",
      "  batch (30/40), train loss:0.7285\n",
      "epoch: 1, time: 0.00, valid_metric: 0.40, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7357\n",
      "  batch (10/40), train loss:0.7058\n",
      "  batch (20/40), train loss:0.7155\n",
      "  batch (30/40), train loss:0.7266\n",
      "epoch: 2, time: 0.00, valid_metric: 0.40, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7339\n",
      "  batch (10/40), train loss:0.7054\n",
      "  batch (20/40), train loss:0.7133\n",
      "  batch (30/40), train loss:0.7248\n",
      "epoch: 3, time: 0.00, valid_metric: 0.40, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7321\n",
      "  batch (10/40), train loss:0.7050\n",
      "  batch (20/40), train loss:0.7111\n",
      "  batch (30/40), train loss:0.7230\n",
      "epoch: 4, time: 0.00, valid_metric: 0.40, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7304\n",
      "  batch (10/40), train loss:0.7046\n",
      "  batch (20/40), train loss:0.7089\n",
      "  batch (30/40), train loss:0.7212\n",
      "epoch: 5, time: 0.00, valid_metric: 0.40, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7286\n",
      "  batch (10/40), train loss:0.7042\n",
      "  batch (20/40), train loss:0.7067\n",
      "  batch (30/40), train loss:0.7194\n",
      "epoch: 6, time: 0.00, valid_metric: 0.40, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7269\n",
      "  batch (10/40), train loss:0.7038\n",
      "  batch (20/40), train loss:0.7045\n",
      "  batch (30/40), train loss:0.7176\n",
      "epoch: 7, time: 0.00, valid_metric: 0.40, train_metric: 0.30\n",
      "  batch (0/40), train loss:0.7252\n",
      "  batch (10/40), train loss:0.7034\n",
      "  batch (20/40), train loss:0.7023\n",
      "  batch (30/40), train loss:0.7159\n",
      "epoch: 8, time: 0.00, valid_metric: 0.40, train_metric: 0.30\n",
      "  batch (0/40), train loss:0.7234\n",
      "  batch (10/40), train loss:0.7030\n",
      "  batch (20/40), train loss:0.7001\n",
      "  batch (30/40), train loss:0.7141\n",
      "epoch: 9, time: 0.00, valid_metric: 0.40, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7217\n",
      "  batch (10/40), train loss:0.7026\n",
      "  batch (20/40), train loss:0.6979\n",
      "  batch (30/40), train loss:0.7124\n",
      "epoch: 10, time: 0.00, valid_metric: 0.40, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7200\n",
      "  batch (10/40), train loss:0.7022\n",
      "  batch (20/40), train loss:0.6957\n",
      "  batch (30/40), train loss:0.7106\n",
      "epoch: 11, time: 0.00, valid_metric: 0.40, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7183\n",
      "  batch (10/40), train loss:0.7018\n",
      "  batch (20/40), train loss:0.6936\n",
      "  batch (30/40), train loss:0.7089\n",
      "epoch: 12, time: 0.00, valid_metric: 0.40, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7166\n",
      "  batch (10/40), train loss:0.7015\n",
      "  batch (20/40), train loss:0.6914\n",
      "  batch (30/40), train loss:0.7071\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7149\n",
      "  batch (10/40), train loss:0.7011\n",
      "  batch (20/40), train loss:0.6893\n",
      "  batch (30/40), train loss:0.7054\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7133\n",
      "  batch (10/40), train loss:0.7007\n",
      "  batch (20/40), train loss:0.6872\n",
      "  batch (30/40), train loss:0.7037\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7116\n",
      "  batch (10/40), train loss:0.7004\n",
      "  batch (20/40), train loss:0.6850\n",
      "  batch (30/40), train loss:0.7020\n",
      "epoch: 16, time: 0.00, valid_metric: 0.50, train_metric: 0.35\n",
      "  batch (0/40), train loss:0.7099\n",
      "  batch (10/40), train loss:0.7000\n",
      "  batch (20/40), train loss:0.6829\n",
      "  batch (30/40), train loss:0.7003\n",
      "epoch: 17, time: 0.00, valid_metric: 0.50, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7083\n",
      "  batch (10/40), train loss:0.6997\n",
      "  batch (20/40), train loss:0.6808\n",
      "  batch (30/40), train loss:0.6987\n",
      "epoch: 18, time: 0.00, valid_metric: 0.50, train_metric: 0.35\n",
      "  batch (0/40), train loss:0.7066\n",
      "  batch (10/40), train loss:0.6993\n",
      "  batch (20/40), train loss:0.6786\n",
      "  batch (30/40), train loss:0.6970\n",
      "epoch: 19, time: 0.00, valid_metric: 0.50, train_metric: 0.35\n",
      "  batch (0/40), train loss:0.7050\n",
      "  batch (10/40), train loss:0.6990\n",
      "  batch (20/40), train loss:0.6765\n",
      "  batch (30/40), train loss:0.6953\n",
      "epoch: 20, time: 0.00, valid_metric: 0.40, train_metric: 0.38\n",
      "  batch (0/40), train loss:0.7033\n",
      "  batch (10/40), train loss:0.6987\n",
      "  batch (20/40), train loss:0.6744\n",
      "  batch (30/40), train loss:0.6937\n",
      "epoch: 21, time: 0.00, valid_metric: 0.40, train_metric: 0.38\n",
      "  batch (0/40), train loss:0.7017\n",
      "  batch (10/40), train loss:0.6984\n",
      "  batch (20/40), train loss:0.6723\n",
      "  batch (30/40), train loss:0.6920\n",
      "epoch: 22, time: 0.00, valid_metric: 0.40, train_metric: 0.38\n",
      "  batch (0/40), train loss:0.7001\n",
      "  batch (10/40), train loss:0.6981\n",
      "  batch (20/40), train loss:0.6702\n",
      "  batch (30/40), train loss:0.6904\n",
      "total train time:0.19 for epochs: 23\n",
      "30\n",
      "  batch (0/40), train loss:0.6886\n",
      "  batch (10/40), train loss:0.7267\n",
      "  batch (20/40), train loss:0.6399\n",
      "  batch (30/40), train loss:0.6978\n",
      "epoch: 0, time: 0.00, valid_metric: 0.70, train_metric: 0.90\n",
      "  batch (0/40), train loss:0.4900\n",
      "  batch (10/40), train loss:0.5005\n",
      "  batch (20/40), train loss:0.4926\n",
      "  batch (30/40), train loss:0.5596\n",
      "epoch: 1, time: 0.00, valid_metric: 0.70, train_metric: 0.90\n",
      "  batch (0/40), train loss:0.3665\n",
      "  batch (10/40), train loss:0.3920\n",
      "  batch (20/40), train loss:0.3707\n",
      "  batch (30/40), train loss:0.4596\n",
      "epoch: 2, time: 0.01, valid_metric: 0.70, train_metric: 0.90\n",
      "  batch (0/40), train loss:0.2818\n",
      "  batch (10/40), train loss:0.3013\n",
      "  batch (20/40), train loss:0.2902\n",
      "  batch (30/40), train loss:0.3737\n",
      "epoch: 3, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2269\n",
      "  batch (10/40), train loss:0.2309\n",
      "  batch (20/40), train loss:0.2279\n",
      "  batch (30/40), train loss:0.3156\n",
      "epoch: 4, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1921\n",
      "  batch (10/40), train loss:0.1812\n",
      "  batch (20/40), train loss:0.1835\n",
      "  batch (30/40), train loss:0.2808\n",
      "epoch: 5, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1678\n",
      "  batch (10/40), train loss:0.1432\n",
      "  batch (20/40), train loss:0.1517\n",
      "  batch (30/40), train loss:0.2434\n",
      "epoch: 6, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1477\n",
      "  batch (10/40), train loss:0.1142\n",
      "  batch (20/40), train loss:0.1289\n",
      "  batch (30/40), train loss:0.2230\n",
      "epoch: 7, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1295\n",
      "  batch (10/40), train loss:0.0924\n",
      "  batch (20/40), train loss:0.1121\n",
      "  batch (30/40), train loss:0.2018\n",
      "epoch: 8, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1137\n",
      "  batch (10/40), train loss:0.0748\n",
      "  batch (20/40), train loss:0.1011\n",
      "  batch (30/40), train loss:0.1872\n",
      "epoch: 9, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1013\n",
      "  batch (10/40), train loss:0.0612\n",
      "  batch (20/40), train loss:0.0914\n",
      "  batch (30/40), train loss:0.1788\n",
      "epoch: 10, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0913\n",
      "  batch (10/40), train loss:0.0511\n",
      "  batch (20/40), train loss:0.0819\n",
      "  batch (30/40), train loss:0.1641\n",
      "epoch: 11, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0803\n",
      "  batch (10/40), train loss:0.0432\n",
      "  batch (20/40), train loss:0.0746\n",
      "  batch (30/40), train loss:0.1544\n",
      "epoch: 12, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0718\n",
      "  batch (10/40), train loss:0.0368\n",
      "  batch (20/40), train loss:0.0682\n",
      "  batch (30/40), train loss:0.1443\n",
      "epoch: 13, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0646\n",
      "  batch (10/40), train loss:0.0320\n",
      "  batch (20/40), train loss:0.0625\n",
      "  batch (30/40), train loss:0.1367\n",
      "epoch: 14, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0590\n",
      "  batch (10/40), train loss:0.0283\n",
      "  batch (20/40), train loss:0.0580\n",
      "  batch (30/40), train loss:0.1310\n",
      "epoch: 15, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0510\n",
      "  batch (10/40), train loss:0.0254\n",
      "  batch (20/40), train loss:0.0541\n",
      "  batch (30/40), train loss:0.1260\n",
      "total train time:0.43 for epochs: 16\n",
      "  batch (0/40), train loss:0.7390\n",
      "  batch (10/40), train loss:0.6905\n",
      "  batch (20/40), train loss:0.7375\n",
      "  batch (30/40), train loss:0.7166\n",
      "epoch: 0, time: 0.00, valid_metric: 0.30, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7372\n",
      "  batch (10/40), train loss:0.6903\n",
      "  batch (20/40), train loss:0.7352\n",
      "  batch (30/40), train loss:0.7147\n",
      "epoch: 1, time: 0.00, valid_metric: 0.30, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7354\n",
      "  batch (10/40), train loss:0.6901\n",
      "  batch (20/40), train loss:0.7329\n",
      "  batch (30/40), train loss:0.7129\n",
      "epoch: 2, time: 0.00, valid_metric: 0.30, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7337\n",
      "  batch (10/40), train loss:0.6899\n",
      "  batch (20/40), train loss:0.7305\n",
      "  batch (30/40), train loss:0.7110\n",
      "epoch: 3, time: 0.00, valid_metric: 0.30, train_metric: 0.30\n",
      "  batch (0/40), train loss:0.7319\n",
      "  batch (10/40), train loss:0.6898\n",
      "  batch (20/40), train loss:0.7282\n",
      "  batch (30/40), train loss:0.7091\n",
      "epoch: 4, time: 0.00, valid_metric: 0.30, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7301\n",
      "  batch (10/40), train loss:0.6896\n",
      "  batch (20/40), train loss:0.7258\n",
      "  batch (30/40), train loss:0.7073\n",
      "epoch: 5, time: 0.00, valid_metric: 0.30, train_metric: 0.35\n",
      "  batch (0/40), train loss:0.7284\n",
      "  batch (10/40), train loss:0.6894\n",
      "  batch (20/40), train loss:0.7234\n",
      "  batch (30/40), train loss:0.7054\n",
      "epoch: 6, time: 0.00, valid_metric: 0.30, train_metric: 0.35\n",
      "  batch (0/40), train loss:0.7266\n",
      "  batch (10/40), train loss:0.6893\n",
      "  batch (20/40), train loss:0.7211\n",
      "  batch (30/40), train loss:0.7035\n",
      "epoch: 7, time: 0.00, valid_metric: 0.30, train_metric: 0.35\n",
      "  batch (0/40), train loss:0.7249\n",
      "  batch (10/40), train loss:0.6891\n",
      "  batch (20/40), train loss:0.7187\n",
      "  batch (30/40), train loss:0.7016\n",
      "epoch: 8, time: 0.00, valid_metric: 0.30, train_metric: 0.33\n",
      "  batch (0/40), train loss:0.7232\n",
      "  batch (10/40), train loss:0.6890\n",
      "  batch (20/40), train loss:0.7164\n",
      "  batch (30/40), train loss:0.6997\n",
      "epoch: 9, time: 0.00, valid_metric: 0.30, train_metric: 0.40\n",
      "  batch (0/40), train loss:0.7215\n",
      "  batch (10/40), train loss:0.6889\n",
      "  batch (20/40), train loss:0.7140\n",
      "  batch (30/40), train loss:0.6978\n",
      "epoch: 10, time: 0.00, valid_metric: 0.30, train_metric: 0.42\n",
      "  batch (0/40), train loss:0.7197\n",
      "  batch (10/40), train loss:0.6887\n",
      "  batch (20/40), train loss:0.7117\n",
      "  batch (30/40), train loss:0.6959\n",
      "epoch: 11, time: 0.00, valid_metric: 0.30, train_metric: 0.42\n",
      "  batch (0/40), train loss:0.7180\n",
      "  batch (10/40), train loss:0.6886\n",
      "  batch (20/40), train loss:0.7094\n",
      "  batch (30/40), train loss:0.6941\n",
      "epoch: 12, time: 0.00, valid_metric: 0.30, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.7164\n",
      "  batch (10/40), train loss:0.6885\n",
      "  batch (20/40), train loss:0.7071\n",
      "  batch (30/40), train loss:0.6922\n",
      "epoch: 13, time: 0.00, valid_metric: 0.30, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.7148\n",
      "  batch (10/40), train loss:0.6884\n",
      "  batch (20/40), train loss:0.7048\n",
      "  batch (30/40), train loss:0.6903\n",
      "epoch: 14, time: 0.00, valid_metric: 0.40, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.7131\n",
      "  batch (10/40), train loss:0.6883\n",
      "  batch (20/40), train loss:0.7025\n",
      "  batch (30/40), train loss:0.6885\n",
      "epoch: 15, time: 0.00, valid_metric: 0.40, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.7115\n",
      "  batch (10/40), train loss:0.6883\n",
      "  batch (20/40), train loss:0.7002\n",
      "  batch (30/40), train loss:0.6866\n",
      "epoch: 16, time: 0.00, valid_metric: 0.40, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.7099\n",
      "  batch (10/40), train loss:0.6882\n",
      "  batch (20/40), train loss:0.6979\n",
      "  batch (30/40), train loss:0.6848\n",
      "epoch: 17, time: 0.00, valid_metric: 0.40, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.7083\n",
      "  batch (10/40), train loss:0.6881\n",
      "  batch (20/40), train loss:0.6957\n",
      "  batch (30/40), train loss:0.6830\n",
      "epoch: 18, time: 0.00, valid_metric: 0.40, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.7067\n",
      "  batch (10/40), train loss:0.6881\n",
      "  batch (20/40), train loss:0.6934\n",
      "  batch (30/40), train loss:0.6812\n",
      "epoch: 19, time: 0.00, valid_metric: 0.40, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.7051\n",
      "  batch (10/40), train loss:0.6880\n",
      "  batch (20/40), train loss:0.6912\n",
      "  batch (30/40), train loss:0.6794\n",
      "epoch: 20, time: 0.00, valid_metric: 0.40, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.7035\n",
      "  batch (10/40), train loss:0.6880\n",
      "  batch (20/40), train loss:0.6890\n",
      "  batch (30/40), train loss:0.6776\n",
      "epoch: 21, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.7020\n",
      "  batch (10/40), train loss:0.6879\n",
      "  batch (20/40), train loss:0.6867\n",
      "  batch (30/40), train loss:0.6758\n",
      "epoch: 22, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.7004\n",
      "  batch (10/40), train loss:0.6879\n",
      "  batch (20/40), train loss:0.6845\n",
      "  batch (30/40), train loss:0.6740\n",
      "epoch: 23, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6988\n",
      "  batch (10/40), train loss:0.6879\n",
      "  batch (20/40), train loss:0.6823\n",
      "  batch (30/40), train loss:0.6723\n",
      "epoch: 24, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6973\n",
      "  batch (10/40), train loss:0.6879\n",
      "  batch (20/40), train loss:0.6801\n",
      "  batch (30/40), train loss:0.6705\n",
      "epoch: 25, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6957\n",
      "  batch (10/40), train loss:0.6879\n",
      "  batch (20/40), train loss:0.6779\n",
      "  batch (30/40), train loss:0.6688\n",
      "epoch: 26, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6942\n",
      "  batch (10/40), train loss:0.6879\n",
      "  batch (20/40), train loss:0.6757\n",
      "  batch (30/40), train loss:0.6671\n",
      "epoch: 27, time: 0.00, valid_metric: 0.60, train_metric: 0.60\n",
      "  batch (0/40), train loss:0.6927\n",
      "  batch (10/40), train loss:0.6879\n",
      "  batch (20/40), train loss:0.6735\n",
      "  batch (30/40), train loss:0.6653\n",
      "epoch: 28, time: 0.00, valid_metric: 0.70, train_metric: 0.60\n",
      "  batch (0/40), train loss:0.6912\n",
      "  batch (10/40), train loss:0.6879\n",
      "  batch (20/40), train loss:0.6714\n",
      "  batch (30/40), train loss:0.6636\n",
      "epoch: 29, time: 0.00, valid_metric: 0.80, train_metric: 0.60\n",
      "  batch (0/40), train loss:0.6896\n",
      "  batch (10/40), train loss:0.6880\n",
      "  batch (20/40), train loss:0.6692\n",
      "  batch (30/40), train loss:0.6619\n",
      "epoch: 30, time: 0.00, valid_metric: 0.70, train_metric: 0.68\n",
      "  batch (0/40), train loss:0.6881\n",
      "  batch (10/40), train loss:0.6880\n",
      "  batch (20/40), train loss:0.6671\n",
      "  batch (30/40), train loss:0.6602\n",
      "epoch: 31, time: 0.00, valid_metric: 0.60, train_metric: 0.70\n",
      "  batch (0/40), train loss:0.6866\n",
      "  batch (10/40), train loss:0.6881\n",
      "  batch (20/40), train loss:0.6649\n",
      "  batch (30/40), train loss:0.6585\n",
      "epoch: 32, time: 0.00, valid_metric: 0.60, train_metric: 0.68\n",
      "  batch (0/40), train loss:0.6852\n",
      "  batch (10/40), train loss:0.6881\n",
      "  batch (20/40), train loss:0.6627\n",
      "  batch (30/40), train loss:0.6568\n",
      "epoch: 33, time: 0.00, valid_metric: 0.70, train_metric: 0.75\n",
      "  batch (0/40), train loss:0.6837\n",
      "  batch (10/40), train loss:0.6882\n",
      "  batch (20/40), train loss:0.6605\n",
      "  batch (30/40), train loss:0.6551\n",
      "epoch: 34, time: 0.00, valid_metric: 0.70, train_metric: 0.75\n",
      "  batch (0/40), train loss:0.6822\n",
      "  batch (10/40), train loss:0.6882\n",
      "  batch (20/40), train loss:0.6584\n",
      "  batch (30/40), train loss:0.6534\n",
      "epoch: 35, time: 0.00, valid_metric: 0.70, train_metric: 0.75\n",
      "  batch (0/40), train loss:0.6807\n",
      "  batch (10/40), train loss:0.6883\n",
      "  batch (20/40), train loss:0.6561\n",
      "  batch (30/40), train loss:0.6518\n",
      "epoch: 36, time: 0.00, valid_metric: 0.70, train_metric: 0.75\n",
      "  batch (0/40), train loss:0.6792\n",
      "  batch (10/40), train loss:0.6884\n",
      "  batch (20/40), train loss:0.6539\n",
      "  batch (30/40), train loss:0.6501\n",
      "epoch: 37, time: 0.00, valid_metric: 0.70, train_metric: 0.75\n",
      "  batch (0/40), train loss:0.6777\n",
      "  batch (10/40), train loss:0.6885\n",
      "  batch (20/40), train loss:0.6516\n",
      "  batch (30/40), train loss:0.6484\n",
      "epoch: 38, time: 0.00, valid_metric: 0.70, train_metric: 0.75\n",
      "  batch (0/40), train loss:0.6762\n",
      "  batch (10/40), train loss:0.6886\n",
      "  batch (20/40), train loss:0.6494\n",
      "  batch (30/40), train loss:0.6467\n",
      "total train time:0.22 for epochs: 39\n",
      "  batch (0/40), train loss:0.6731\n",
      "  batch (10/40), train loss:0.7145\n",
      "  batch (20/40), train loss:0.6816\n",
      "  batch (30/40), train loss:0.6988\n",
      "epoch: 0, time: 0.00, valid_metric: 0.30, train_metric: 0.72\n",
      "  batch (0/40), train loss:0.5085\n",
      "  batch (10/40), train loss:0.5873\n",
      "  batch (20/40), train loss:0.5490\n",
      "  batch (30/40), train loss:0.5562\n",
      "epoch: 1, time: 0.00, valid_metric: 0.30, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.3793\n",
      "  batch (10/40), train loss:0.5024\n",
      "  batch (20/40), train loss:0.4402\n",
      "  batch (30/40), train loss:0.4508\n",
      "epoch: 2, time: 0.00, valid_metric: 0.20, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.2908\n",
      "  batch (10/40), train loss:0.4342\n",
      "  batch (20/40), train loss:0.3582\n",
      "  batch (30/40), train loss:0.3815\n",
      "epoch: 3, time: 0.00, valid_metric: 0.20, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2128\n",
      "  batch (10/40), train loss:0.3790\n",
      "  batch (20/40), train loss:0.3110\n",
      "  batch (30/40), train loss:0.3285\n",
      "epoch: 4, time: 0.00, valid_metric: 0.20, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.1593\n",
      "  batch (10/40), train loss:0.3334\n",
      "  batch (20/40), train loss:0.2667\n",
      "  batch (30/40), train loss:0.2854\n",
      "epoch: 5, time: 0.00, valid_metric: 0.20, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.1210\n",
      "  batch (10/40), train loss:0.2931\n",
      "  batch (20/40), train loss:0.2322\n",
      "  batch (30/40), train loss:0.2473\n",
      "epoch: 6, time: 0.00, valid_metric: 0.20, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.0918\n",
      "  batch (10/40), train loss:0.2587\n",
      "  batch (20/40), train loss:0.2094\n",
      "  batch (30/40), train loss:0.2226\n",
      "epoch: 7, time: 0.00, valid_metric: 0.20, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.0705\n",
      "  batch (10/40), train loss:0.2266\n",
      "  batch (20/40), train loss:0.1876\n",
      "  batch (30/40), train loss:0.2015\n",
      "epoch: 8, time: 0.00, valid_metric: 0.20, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0552\n",
      "  batch (10/40), train loss:0.1995\n",
      "  batch (20/40), train loss:0.1696\n",
      "  batch (30/40), train loss:0.1664\n",
      "epoch: 9, time: 0.00, valid_metric: 0.20, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0445\n",
      "  batch (10/40), train loss:0.1755\n",
      "  batch (20/40), train loss:0.1575\n",
      "  batch (30/40), train loss:0.1313\n",
      "epoch: 10, time: 0.00, valid_metric: 0.20, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0368\n",
      "  batch (10/40), train loss:0.1552\n",
      "  batch (20/40), train loss:0.1469\n",
      "  batch (30/40), train loss:0.1071\n",
      "epoch: 11, time: 0.00, valid_metric: 0.20, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0313\n",
      "  batch (10/40), train loss:0.1379\n",
      "  batch (20/40), train loss:0.1386\n",
      "  batch (30/40), train loss:0.0922\n",
      "epoch: 12, time: 0.00, valid_metric: 0.30, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0267\n",
      "  batch (10/40), train loss:0.1231\n",
      "  batch (20/40), train loss:0.1311\n",
      "  batch (30/40), train loss:0.0806\n",
      "epoch: 13, time: 0.00, valid_metric: 0.30, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0234\n",
      "  batch (10/40), train loss:0.1105\n",
      "  batch (20/40), train loss:0.1244\n",
      "  batch (30/40), train loss:0.0722\n",
      "epoch: 14, time: 0.00, valid_metric: 0.30, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0205\n",
      "  batch (10/40), train loss:0.0985\n",
      "  batch (20/40), train loss:0.1193\n",
      "  batch (30/40), train loss:0.0654\n",
      "epoch: 15, time: 0.00, valid_metric: 0.30, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0183\n",
      "  batch (10/40), train loss:0.0843\n",
      "  batch (20/40), train loss:0.1139\n",
      "  batch (30/40), train loss:0.0595\n",
      "epoch: 16, time: 0.00, valid_metric: 0.30, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0166\n",
      "  batch (10/40), train loss:0.0729\n",
      "  batch (20/40), train loss:0.1097\n",
      "  batch (30/40), train loss:0.0541\n",
      "epoch: 17, time: 0.00, valid_metric: 0.30, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0152\n",
      "  batch (10/40), train loss:0.0645\n",
      "  batch (20/40), train loss:0.1064\n",
      "  batch (30/40), train loss:0.0494\n",
      "epoch: 18, time: 0.00, valid_metric: 0.30, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0140\n",
      "  batch (10/40), train loss:0.0574\n",
      "  batch (20/40), train loss:0.1030\n",
      "  batch (30/40), train loss:0.0452\n",
      "epoch: 19, time: 0.00, valid_metric: 0.30, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0129\n",
      "  batch (10/40), train loss:0.0517\n",
      "  batch (20/40), train loss:0.1001\n",
      "  batch (30/40), train loss:0.0416\n",
      "epoch: 20, time: 0.00, valid_metric: 0.30, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0120\n",
      "  batch (10/40), train loss:0.0468\n",
      "  batch (20/40), train loss:0.0976\n",
      "  batch (30/40), train loss:0.0384\n",
      "epoch: 21, time: 0.00, valid_metric: 0.30, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0111\n",
      "  batch (10/40), train loss:0.0425\n",
      "  batch (20/40), train loss:0.0955\n",
      "  batch (30/40), train loss:0.0355\n",
      "total train time:0.50 for epochs: 22\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3024da697ee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;31m# cleanup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/academic/gene-graph-conv/models/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs, probs)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGet\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mestimates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for row in todo:\n",
    "    if len(results) % 10 == 0:\n",
    "        print(len(results))\n",
    "    gene = row[\"gene\"]\n",
    "    graph_name = row[\"graph\"]\n",
    "    model_name = row[\"model\"]\n",
    "    seed = row[\"seed\"]\n",
    "    is_first_degree = row[\"is_first_degree\"]\n",
    "    model = models[model_name]\n",
    "\n",
    "    experiment = {\n",
    "        \"gene\": gene,\n",
    "        \"model\": model_name,\n",
    "        \"graph\": graph_name,\n",
    "        \"is_first_degree\": is_first_degree,\n",
    "        \"seed\": seed,\n",
    "        \"train_size\": train_size,\n",
    "    }\n",
    "    dataset.labels = dataset.df[gene].where(dataset.df[gene] > 0).notnull().astype(\"int\")\n",
    "    dataset.labels = dataset.labels.values if type(dataset.labels) == pd.Series else dataset.labels\n",
    "\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = sklearn.model_selection.\\\n",
    "            train_test_split(dataset.df, dataset.labels, stratify=dataset.labels, \n",
    "                             train_size=train_size, test_size=test_size)\n",
    "    except ValueError:\n",
    "        results = record_result(results, experiment, filename)\n",
    "        continue\n",
    "    if is_first_degree:\n",
    "        gene_graph = graphs[graph_name]\n",
    "        neighbors = list(gene_graph.first_degree(gene)[0])\n",
    "        neighbors = [n for n in neighbors if n in X_train.columns.values]\n",
    "        X_train = X_train.loc[:, neighbors].copy()\n",
    "        X_test = X_test.loc[:, neighbors].copy()\n",
    "    else:\n",
    "        X_train = X_train.copy()\n",
    "        X_test = X_test.copy()\n",
    "    X_train[gene] = 1\n",
    "    X_test[gene] = 1\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        if cuda:\n",
    "            X_test = X_test.cuda()\n",
    "        y_hat = model.predict(X_test)\n",
    "        auc = sklearn.metrics.roc_auc_score(y_test, np.argmax(y_hat, axis=1))\n",
    "        model.best_model = None # cleanup\n",
    "        experiment[\"auc\"] = auc\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    results = record_result(results, experiment, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the performance of each graph at predicting their neighbors\n",
    "df = results\n",
    "\n",
    "first_degree = df[df['is_first_degree'] == True][\n",
    "    df['graph'] == 'genemania'].groupby(['gene', 'model', 'train_size'])['auc'].agg(['mean', 'std'])\n",
    "full = df[df['is_first_degree'] == False][\n",
    "    df['graph'] == 'genemania'].groupby(['gene','model', 'train_size'])['auc'].agg(['mean', 'std'])\n",
    "genemania_df = first_degree.sub(full).sort_values('mean', ascending=False)\n",
    "\n",
    "first_degree = df[df['is_first_degree'] == True][\n",
    "    df['graph'] == 'regnet'].groupby(['gene', 'model', 'train_size'])['auc'].agg(['mean', 'std'])\n",
    "full = df[df['is_first_degree'] == False][\n",
    "    df['graph'] == 'regnet'].groupby(['gene','model', 'train_size'])['auc'].agg(['mean', 'std'])\n",
    "regnet_df = first_degree.sub(full).sort_values('mean', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/code/academic/gene-graph-conv/venv/lib/python3.5/site-packages/numpy/lib/histograms.py:754: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/home/martin/code/academic/gene-graph-conv/venv/lib/python3.5/site-packages/numpy/lib/histograms.py:755: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "l1 = genemania_df['mean']\n",
    "l2 = regnet_df['mean']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "n1, bins1, patches1 = ax.hist(l1, range=(-.4, .25), bins=100, label=\"Regnet\", \n",
    "                              density=0, alpha=0.55, histtype='step')\n",
    "n1, bins1, patches1 = ax.hist(l2, range=(-.4, .25), bins=100, label=\"GeneMania\", \n",
    "                              density=0, alpha=0.55, histtype='step')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "n1, bins1, patches1 = ax.hist(l1, range=(-.4, .25), bins=100, label=\"Regnet\", \n",
    "                              density=0, alpha=0.55, histtype='step')\n",
    "n1, bins1, patches1 = ax.hist(l2, range=(-.4, .25), bins=100, label=\"GeneMania\", \n",
    "                              density=0, alpha=0.55, histtype='step')\n",
    "\n",
    "plt.title(\"First Degree Neighbors vs Full Gene Set\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"% AUC Improvement\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
